import math
import time
import logging
import os
import math
from os.path import join as pjoin
from collections import OrderedDict

import numpy as np
from tqdm import tqdm
import torch
import torch.nn.functional as F
from torch.utils.data import SubsetRandomSampler

from utils.hard_concrete import get_hardconcrete_modules
from utils.eval_utils import get_rouge, ngram_overlap
from models.utils import find_pruneable_heads_and_indices, robust_load_state_dict
import pdb

class Trainer:

    def __init__(self, args, model, train_loader, val_loader, optim, checkpoint=None, target_val_loss=None, **kwargs):

        self.device = args.device
        self.model = model.to(args.device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.dynamic_attn_mask = (args.summarizer_type == 'oursum')


        # self.use_tree = (args.discourse_tree_attn or args.use_all_attn)
        self.optim = optim
        self.report_steps=args.report_steps
        self.train_steps = args.train_steps
        self.save_checkpoint_steps = args.save_checkpoint_steps
        self.accum_batch_size = args.accum_batch_size
        # self.loss_function = torch.nn.BCELoss(reduction='none')
        self.ckpt_dir = pjoin(args.result_dir, 'checkpoints')
        self.result_dir=args.result_dir
        self.block_trigram=args.block_trigram
        self.limit_length = args.limit_length
        self.rouge_metric = args.rouge_metric
        self.top_n = args.top_n
        if not os.path.exists(self.ckpt_dir):
            os.makedirs(self.ckpt_dir, exist_ok=True)

        self.encoder_type = args.encoder_type
        # self.curr_epoch_loss = 0.
        # self.curr_epoch_idx_trained = set()
        # self.epoch_losses = []
        self.steps_trained = 0
        # self.epochs_trained = 0
        # self.steps_trained_in_current_epoch = 0

        self.avoid_saving_steps = args.avoid_saving_steps

        self.acc_loss = 0
        self.target_val_loss = target_val_loss

        self.validation_metric = args.valid_metric
        self.top_validation_scores = np.full(args.top_n_ckpts, np.inf)
        # self.top_validation_avgrouge = np.full(args.top_n_ckpts, np.inf)
        self.top_ckpt_steps = np.full(args.top_n_ckpts, 0)
        self.top_ckpt_path = []

        self.max_input_len = args.max_input_len
        # self.n_samples = len(self.train_loader.dataset)

        self.n_samples = 200000 #fake number 
        self.samples_per_step = math.ceil(self.accum_batch_size / args.batch_size) * args.batch_size
        # self.steps_per_epoch = math.ceil(self.n_samples / self.samples_per_step)
        self.train_epochs = math.ceil(self.train_steps / (self.n_samples / self.samples_per_step))

        # self.l0_prune = args.l0_prune
        self.l0_prune = False
        if self.l0_prune:
            # self.lambda_optim = kwargs['lambda_optim']
            # self.target_sparsity = kwargs['target_sparsity']
            self.old_params = kwargs['old_params']
            self.new_params = kwargs['new_params']
            self.num_prunable_params = kwargs['num_prunable_params']
            self.hc_modules = get_hardconcrete_modules(self.model)
            # self.prune_warmup = kwargs['prune_warmup']
            self.lambda_l0 = 2


        self.logger = logging.getLogger()
        # self.pbar = tqdm(total=(self.train_epochs * self.steps_per_epoch))

        if checkpoint != None:
            self.load_checkpoint(checkpoint)

        n_params = sum([p.nelement() for p in model.parameters()])
        self.logger.info(f'Total number of parameters: {n_params}')

    def load_checkpoint(self, checkpoint):
        if self.l0_prune:

            # Update parameters for model
            new_model_state = OrderedDict()
            for key, value in checkpoint['model'].items():
                key_items = key.split('.')
                if 'attention' in key_items:
                    idx = key_items.index('attention')
                    key_items.insert(idx, 'attention')
                    key = '.'.join(key_items)
                new_model_state[key] = value

            
            # # Update all keys in 'param_groups' except for 'params'
            new_optimizer_state = self.optim.optimizer.state_dict()
            # param_groups_keys = list(new_optimizer_state['param_groups'][0].keys())
            # param_groups_keys.remove('params')
            # for key in param_groups_keys:
            #     new_optimizer_state['param_groups'][0][key] = checkpoint['optim']['param_groups'][0][key]

            # # Update parameters for Adam optimizer 'state'
            # for name, new_idx in self.new_params.items():
            #     if name in self.old_params.keys():
            #         old_idx = self.old_params[name]
            #         try:
            #             new_optimizer_state['state'][new_idx] = checkpoint['optim']['state'][old_idx]
            #         except:
            #             continue
            #     else:
            #         # State initialization
            #         state = {}
            #         state['step'] = checkpoint['steps_trained']
            #         state['exp_avg'] = torch.zeros_like(self.model.state_dict()[name],
            #                                             memory_format=torch.preserve_format)
            #         state['exp_avg_sq'] = torch.zeros_like(self.model.state_dict()[name],
            #                                                memory_format=torch.preserve_format)
            #         new_optimizer_state['state'][new_idx] = state

            del checkpoint['model']
            del checkpoint['optim']
            checkpoint['model'] = new_model_state
            checkpoint['optim'] = new_optimizer_state

        try:
            self.model.load_state_dict(checkpoint['model'], strict=True)
        except RuntimeError:
            robust_load_state_dict(self.model, checkpoint['model'])

        self.optim.optimizer.load_state_dict(checkpoint['optim'])
        self.optim.lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])
        self.optim.optimizer.zero_grad()

        # Add Hard-Concrete parameters to the optimizer
        # if self.l0_prune:
        #     params_to_add = list(set(self.model.state_dict().keys()).difference(set(new_model_state.keys())))
        #     params_to_add = [self.model.state_dict()[param] for param in params_to_add]
        #     pdb.set_trace
        #     self.optim.optimizer.param_groups[0].append({'params': params_to_add})
            # self.optim.optimizer.add_param_group({'params': params_to_add})

        # Ensure the state values are consistent in the checkpoint
        try:
            assert checkpoint['steps_trained'] == self.optim.lr_scheduler.last_epoch
            # assert checkpoint['epochs_trained'] == math.floor(self.optim.lr_scheduler.last_epoch / self.steps_per_epoch)
            # assert checkpoint['steps_trained_in_current_epoch'] == self.optim.lr_scheduler.last_epoch % self.steps_per_epoch
            # assert len(checkpoint['curr_epoch_idx_trained']) // self.samples_per_step  == checkpoint['steps_trained_in_current_epoch']
        except:
            pdb.set_trace()

        self.steps_trained = checkpoint['steps_trained']
        # self.epochs_trained = checkpoint['epochs_trained']
        # self.steps_trained_in_current_epoch = checkpoint['steps_trained_in_current_epoch']
        # self.curr_epoch_loss = checkpoint['curr_epoch_loss']
        # self.curr_epoch_idx_trained = checkpoint['curr_epoch_idx_trained']
        # self.epoch_losses = checkpoint['epoch_losses']
        self.acc_loss=checkpoint['avg_loss']*self.steps_trained

        self.logger.info(f"Loaded checkpoint from step {self.steps_trained}")

        # if self.l0_prune:
        #     self.steps_trained = 0
            # self.epochs_trained = 0
            # self.steps_trained_in_current_epoch = 0
            # self.curr_epoch_loss = 0
            # self.curr_epoch_idx_trained = set()
            # self.epoch_losses = []

        del checkpoint
        torch.cuda.empty_cache()


    def save_checkpoint(self, save_name):
        saved_state = {
            'model': self.model.state_dict(),
            'optim': self.optim.optimizer.state_dict() if hasattr(self.optim, 'optimizer') else self.optim.state_dict(),
            'lr_scheduler': self.optim.lr_scheduler.state_dict() if hasattr(self.optim, 'lr_scheduler') else None,
            'steps_trained': self.steps_trained,
            'avg_loss':self.acc_loss/self.steps_trained

            # 'epochs_trained': self.epochs_trained,
            # 'steps_trained_in_current_epoch': self.steps_trained_in_current_epoch,
            # 'curr_epoch_idx_trained': self.curr_epoch_idx_trained,
            # 'curr_epoch_loss': self.curr_epoch_loss,
            # 'epoch_losses': self.epoch_losses
        }
        torch.save(saved_state, pjoin(self.ckpt_dir, save_name))
        del saved_state
        torch.cuda.empty_cache()

    def train(self):
        self.logger.info("***** Running training *****")
        # self.logger.info(f"  Num examples = {self.n_samples}")
        self.logger.info(f"  Total optimization steps = {self.train_steps}")
        # self.logger.info("  Batch  Accumulation steps = %d", self.args.gradient_accumulation_steps)
        
        # If the checkpoint was saved before the epoch was finished, use the subset of unfinished indices
        # if len(self.curr_epoch_idx_trained) > 0:
        #     remaining_idx = list(set(np.arange(self.n_samples)) - self.curr_epoch_idx_trained)
        #     self.cached_sampler = self.train_loader.batch_sampler.sampler
        #     self.train_loader.batch_sampler.sampler = SubsetRandomSampler(remaining_idx)
        #     self.pbar.update(self.steps_trained)

        # Get the dataloader to the same state as before
        if self.steps_trained != 0:
            accum_count = 0
            steps_iterated = 0
            print("Setting the state of the dataloader")
            with tqdm(total=self.steps_trained) as pbar:
                for idx, batch in enumerate(self.train_loader):
                    accum_count += len(batch)
                    if accum_count >= self.accum_batch_size:
                        steps_iterated += 1
                        pbar.update(1)
                        if steps_iterated == self.steps_trained:
                            break


        accum_count = 0
        report_loss_sum = 0.
        start_time = time.time()


        self.model.zero_grad()

        if self.l0_prune:
            # self.lambda_optim.optimizer.zero_grad()
            step_Lc_loss = 0.

        # Update the references
        # for epoch in range(self.epochs_trained, self.train_epochs):
        with tqdm(initial=self.steps_trained, total=self.train_steps) as pbar:
            for idx, batch in enumerate(self.train_loader):
                src_subtoken_idxs = batch.src.to(self.device)
                cls_idx = batch.clss.to(self.device)
                attention_mask = batch.mask.to(self.device)
                cls_mask = batch.mask_cls.to(self.device)
                labels = batch.labels.to(self.device)

                segments_ids = batch.segs.to(self.device)
                sent_mask = batch.sent_mask.to(self.device)
                sent_span = batch.sent_span
                tree_attention = None
                # cls_idx[cls_idx >= self.max_input_len] = 0
                # cls_mask[cls_idx >= self.max_input_len] = 0

                # self.curr_epoch_idx_trained.update(batch.indices)
                accum_count += len(batch)
                # if self.use_tree:
                #     tree_attention=batch.attn_map.to(self.device)

                if self.dynamic_attn_mask:
                    sent_scores = self.model(
                        src_subtoken_idxs,
                        segments_ids,
                        attention_mask,
                        cls_idx,
                        cls_mask,
                        dynamic_attn_mask=self.dynamic_attn_mask,
                        sent_span=sent_span,
                        sent_mask=sent_mask
                    )
                else:
                    sent_scores = self.model(
                        src_subtoken_idxs,
                        segments_ids,
                        attention_mask,
                        cls_idx,
                        cls_mask,
                        sent_span=sent_span,
                        sent_mask=sent_mask
                    )

                del src_subtoken_idxs
                del segments_ids
                del cls_idx
                del attention_mask
                torch.cuda.empty_cache()

                # Predict top-3 
                # if True:
                    # labels[:, :3] = 1
                    # labels[:, 3:] = 0
                    # labels = labels * cls_mask

                # print(sent_scores.shape)
                # print(labels.shape)
                # loss = self.loss_function(sent_scores, labels)
                # loss = (loss * cls_mask).sum()

                # Our classifier already has a sigmoid layer, so no need to use "with logits" 
                loss = F.binary_cross_entropy(sent_scores, labels, reduction='sum')
                loss_value = loss.cpu().data.numpy()
                report_loss_sum += loss_value

                # Perhaps using a running window?
                self.acc_loss += loss_value


                # if self.l0_prune:
                #     expected_size = sum(m.get_l0_penalty() for m in self.hc_modules)
                #     L_c = self.lambda_l0 * expected_size
                #     step_Lc_loss += L_c.cpu().item()
                #     loss = loss + L_c
                    # L_c.backward()

                    # k = 11
                    # # compute target sparsity
                    # target_sparsity = 1 - self.target_sparsity
                    # if self.prune_warmup > 0:
                    #     warmup_sparsity = round((self.steps_trained / self.prune_warmup) * k) / k
                    #     target_sparsity *= min(1.0, warmup_sparsity)

                    # # compute expected sparsity
                    # # hc_modules = get_hardconcrete_linear_modules(self.model)
                    # expected_sparsity = 1.0 - expected_size / self.num_prunable_params
                    # self.logger.info(f"lambda_1: {round(self.lambda_1.cpu().item(), 4)}" +
                    #                  f"lambda_2: {round(self.lambda_2.cpu().item(), 4)}" +
                    #                  f"target_sparsity: {target_sparsity}; expected_sparsity: {expected_sparsity}")

                    # # compute lagrangian loss
                    # lagrangian_loss = self.lambda_1 * (expected_sparsity - target_sparsity) + \
                    #                   self.lambda_2 * (expected_sparsity - target_sparsity)**2
                    # lagrangian_loss.backward()
                    # step_lambda_loss += lagrangian_loss.cpu().data.numpy()

                (loss / loss.numel()).backward()

                if accum_count >= self.accum_batch_size:

                    # self.pbar.update(1)

                    if hasattr(self.optim, 'lr_scheduler'):
                        lr_used = self.optim.lr_scheduler.get_last_lr()[0]
                    else:
                        lr_used = self.optim.param_groups[0]['lr']
                    
                    lr_formatted = np.format_float_scientific(lr_used, unique=False, precision=7)

                    if hasattr(self, 'requires_grad_heads') and hasattr(self, 'require_grad_params'):
                        for name, param in self.model.named_parameters():
                            if name in self.require_grad_params:
                                layer = int(name.split('.')[3])
                                heads = self.requires_grad_heads[layer]
                                config = self.model.encoder.config
                                n_heads = config.num_attention_heads
                                head_size = int(config.hidden_size / n_heads)
                                heads, index = find_pruneable_heads_and_indices(heads, n_heads, head_size, set())
                                index = index.to(self.model.device)

                                if 'attention.self' in name or 'bias' in name:
                                    param.grad[index] = 0
                                elif 'output.dense.weight' in name:
                                    param.grad[:, index] = 0
                                else:
                                    pdb.set_trace()
                    #     if param.requires_grad:
                    #         print(name)
                    # if self.l0_prune:
                        # self.lambda_optim.step()
                        # lambda_lr_used = self.lambda_optim.lr_scheduler.get_last_lr()[0]
                        # lambda_lr_formatted = np.format_float_scientific(lambda_lr_used, unique=False, precision=7)
                        # avg_Lc_loss = round(step_Lc_loss / accum_count, 4)
                    self.optim.step()
                    self.model.zero_grad()

                    # Save some memory
                    del loss
                    torch.cuda.empty_cache()

                    # self.lambda_optim.optimizer.zero_grad()

                    self.steps_trained += 1
                    # self.steps_trained_in_current_epoch += 1


                    if (self.steps_trained % self.report_steps) == 0:


                        # Compute the average loss and training speed for reporting
                        n_docs = self.report_steps * self.accum_batch_size
                        n_docs_per_sec = round(n_docs / (time.time() - start_time), 3)
                        avg_loss = round(report_loss_sum / n_docs, 4)

                        acc_avg_loss = self.acc_loss / (self.steps_trained * self.accum_batch_size)
                        self.logger.info(f"Step {self.steps_trained}; avg loss: {avg_loss}; acc avg loss: {acc_avg_loss}; lr: {lr_formatted}; {n_docs_per_sec} docs/s")

                        report_loss_sum = 0.
                        start_time = time.time()
                        # if self.l0_prune:
                            # self.logger.info(f"Step {self.steps_trained}; avg loss: {avg_loss}; lr: {lr_formatted}; {n_docs_per_sec} docs/s;" +
                                             # f" avg L_c loss: {avg_Lc_loss}; l0_norm: {expected_size.cpu().item()}")
                        # else:

                    # Save checkpoints

                    if (self.steps_trained > self.avoid_saving_steps) and (self.steps_trained % self.save_checkpoint_steps) == 0:


                        val_results = self.validate()

                        # To avoid "." in file name
                        validation_loss = int(round(val_results['loss'], 3) * 1000)
                        save_name = f'step_{self.steps_trained}_loss_{validation_loss}'

                        if self.validation_metric == 'rouge':
                            validation_rouge = int(round(val_results['rouge'], 2) * 100)
                            save_name += f'_rouge_{validation_rouge}'


                        self.save_checkpoint(f"{save_name}.pth")

                        
                        # Keep only top n checkpoints
                        checkpoints = os.listdir(self.ckpt_dir)
                        checkpoints = [ckpt for ckpt in checkpoints if ckpt[-4:] == '.pth']
                        reverse = (self.validation_metric == 'rouge')
                        checkpoints.sort(key=lambda x: int(x.split('.')[0].split('_')[-1]), reverse=reverse)

                        top_n = len(self.top_ckpt_steps)
                        checkpoints = list(map(lambda x: pjoin(self.ckpt_dir, x), checkpoints))

                        if len(checkpoints) <= top_n:
                            self.top_ckpt_path = checkpoints
                        else:
                            self.top_ckpt_path = checkpoints[:top_n]
                            [os.remove(x) for x in checkpoints[top_n:]]

                        self.logger.info(f"Currently {len(self.top_ckpt_path)} checkpoints saved")
                            
                        
                        if (self.target_val_loss != None) and (validation_loss <= self.target_val_loss):
                            return validation_loss
                        

                    accum_count = 0

                    # Update the progress bar
                    pbar.update(1)
                    # step_Lc_loss = 0.
                    # if self.l0_prune:
                        # step_lambda_loss = 0.


                # self.epochs_trained += 1
                # self.steps_trained_in_current_epoch = 0
                # self.curr_epoch_idx_trained.clear()

                # self.logger.info(f"Finished Epoch {self.epochs_trained}; Epoch loss: {self.curr_epoch_loss}")

                # # validation_loss = int(round(self.validate()))   
                # # self.save_checkpoint(f"epoch_{self.epochs_trained}_loss_{validation_loss}.pth")
                # if (self.target_val_loss != None) and (validation_loss <= self.target_val_loss):
                #     return validation_loss

                # self.epoch_losses.append(self.curr_epoch_loss)
                # self.curr_epoch_loss = 0.

                # After the unfinished epoch, revert the batch sampler to index the full training set
                # if hasattr(self, 'cached_sampler'):
                #     self.train_loader.batch_sampler.sampler = self.cached_sampler
                #     del self.cached_sampler



        return self.top_validation_loss[0]

    def validate(self):
        self.model.eval()
        validation_loss = 0.
        candidate_path = pjoin(self.result_dir, 'bert_ext.candidate')
        gold_path = pjoin(self.result_dir, 'bert_ext.gold')

        loss_function = torch.nn.BCELoss(reduction='none')
        all_hyp_path = []
        all_ref_path = []
        n_examples = 0
        with torch.no_grad():
            for i, batch in enumerate(tqdm(self.val_loader)):

                src_subtoken_idxs = batch.src.to(self.device)
                segments_ids = batch.segs.to(self.device)
                cls_idx = batch.clss.to(self.device)
                attention_mask = batch.mask.to(self.device)
                cls_mask = batch.mask_cls.to(self.device)
                labels = batch.labels.to(self.device)
                
                src_txt = batch.src_txt
                tgt_txt = batch.tgt_txt

                tree_attention=None
                sent_span = batch.sent_span.to(self.device)
                sent_mask = batch.sent_mask.to(self.device)


                n_examples += len(batch)
                if self.dynamic_attn_mask:
                    sent_scores = self.model(
                        src_subtoken_idxs,
                        segments_ids,
                        attention_mask,
                        cls_idx,
                        cls_mask,
                        dynamic_attn_mask=self.dynamic_attn_mask,
                        sent_span=sent_span,
                        sent_mask=sent_mask
                    )
                else:
                    sent_scores = self.model(
                        src_subtoken_idxs,
                        segments_ids,
                        attention_mask,
                        cls_idx,
                        cls_mask,
                        sent_span=sent_span,
                        sent_mask=sent_mask
                    )



                loss = F.binary_cross_entropy(sent_scores, labels, reduction='sum')
                validation_loss += loss.cpu().data.numpy()
                
                # Whether to compute ROUGE score for the predictions
                if self.validation_metric == 'rouge':
                    sent_scores = sent_scores + cls_mask
                    sent_scores = sent_scores.cpu().data.numpy()

                    # Sort the sentences by their extractive score
                    sorted_sent_scores = np.argsort(-sent_scores, 1)

                    for batch_idx, _sorted_sent_scores in enumerate(sorted_sent_scores):
                        fid = batch.ids[batch_idx]
                        selected_ids = []
                        pred = []

                        cls_count = cls_mask[batch_idx].float().sum().item()
                        sent_count = sent_mask[batch_idx].sum().item()

                        # Assuming we are using CLS as sentence representations
                        # Comment out as sent count is not correct.
                        # assert cls_count == sent_count

                        # Empty source text
                        if (src_txt[batch_idx] == 0):
                            continue

                        # Form prediction text from the sorted sentence scores 
                        for sent_idx in _sorted_sent_scores:
                            if sent_idx >= sent_count:
                                continue

                            try:
                                candidate = src_txt[batch_idx][sent_idx].strip()
                            except:
                                pdb.set_trace()

                            # pdb.set_trace()
                            if (not self.block_trigram) or (not ngram_overlap(candidate, pred)):
                                selected_ids.append(sent_idx)
                                pred.append(candidate)

                            if len(pred) == self.top_n:
                                break

                        # Predicted summaries are truncated to the length of the gold summaries (NYT)
                        if self.limit_length:
                            n_pred = len(pred)
                            pred = ' <q>'.join(pred).split()
                            pred = pred[:len(tgt_txt[batch_idx].split())]
                            pred = ' '.join(pred).split('<q>')

                        hyp_path = pjoin(candidate_path,'%s.txt'%(fid))
                        with open(hyp_path,'w') as of:
                            order_summ = [y for _,y in sorted(zip(selected_ids,pred),reverse=False)]
                            of.write('\n'.join(pred))


                        ref_path=pjoin(gold_path,'%s.txt'%(fid))
                        with open(ref_path,'w') as of:
                            of.write(tgt_txt[batch_idx])
                        
                        all_ref_path.append(ref_path)
                        all_hyp_path.append(hyp_path)

                    
                    # pred = '<q>'.join(pred)
                    # save_pred.write(pred.strip() + '\n')
                    # save_gold.write(tgt_txt[batch_idx].strip() + '\n')

            # temp_dir = pjoin(args.result_dir, '.tmp')
            # if rouge:
            #     rouges = test_rouge(temp_dir, candidate_path, gold_path)
            #     logger.info(rouge_results_to_str(rouges))
        torch.cuda.empty_cache()
        validation_loss /= n_examples
        output = {'loss': validation_loss}

        if self.validation_metric == 'rouge':
            avg, c, df = get_rouge(all_hyp_path, all_ref_path, config_path=pjoin(self.result_dir,'config'))

            if self.rouge_metric == 'f1':
                score = (avg['rouge-1-f'] + avg['rouge-2-f'] + avg['rouge-L-f']) / 3
            elif self.rouge_metric == 'recall':
                score = (avg['rouge-1-r'] + avg['rouge-2-r'] + avg['rouge-L-r']) / 3
            
            self.logger.info("Rouge-1 r score: %f, Rouge-1 p score: %f, Rouge-1 f-score: %f, 95-conf(%f-%f)"%(\
                    avg['rouge-1-r'],avg['rouge-1-p'],avg['rouge-1-f'],c[0]['lower_conf_f'],c[0]['upper_conf_f']))
            self.logger.info("Rouge-2 r score:%f, Rouge-1 p score: %f, Rouge-2 f-score:%f, 95-conf(%f-%f)"%(\
                avg['rouge-2-r'],avg['rouge-2-p'],avg['rouge-2-f'],c[1]['lower_conf_f'],c[1]['upper_conf_f']))
            self.logger.info("Rouge-L r score:%f, Rouge-1 p score: %f, Rouge-L f-score:%f, 95-conf(%f-%f)"%(\
                avg['rouge-L-r'],avg['rouge-L-p'],avg['rouge-L-f'],c[2]['lower_conf_f'],c[2]['upper_conf_f']))

            score *= 100
            self.logger.info(f"At step {self.steps_trained}, Validation loss : {validation_loss}, Validation AVG Rouge : {score} ")
            output['rouge'] = score

        elif self.validation_metric == 'loss':
            score = validation_loss
            self.logger.info(f"At step {self.steps_trained}, Validation loss : {validation_loss} ")

        # Update the beam of validation scores
        if self.validation_metric == 'rouge':
            update_beam = any([score > x for x in self.top_validation_scores])
            worst_idx = self.top_validation_scores.argmin()
        elif self.validation_metric == 'loss':
            update_beam = any([score < x for x in self.top_validation_scores])
            worst_idx = self.top_validation_scores.argmax()

        if update_beam:
            self.top_validation_scores = np.delete(self.top_validation_scores, worst_idx)
            self.top_validation_scores = np.append(self.top_validation_scores, score)
            indices = self.top_validation_scores.argsort()
            if self.validation_metric == 'rouge':
                indices = indices[::-1]
            self.top_validation_scores = self.top_validation_scores[indices]

            self.top_ckpt_steps = np.delete(self.top_ckpt_steps, worst_idx)
            self.top_ckpt_steps = np.append(self.top_ckpt_steps, self.steps_trained)
            self.top_ckpt_steps = self.top_ckpt_steps[indices]

        # self.logger.info(f"Best performing checkpoint is step {self.top_ckpt_steps[0]}: {self.top_validation_loss[0]}")

        self.model.train()
        return output
