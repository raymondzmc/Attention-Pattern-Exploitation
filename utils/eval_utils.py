from collections import Counter
from pathlib import Path
from rouge_wrapper.rouge import compute_rouge,make_simple_config_text
import pandas as pd
import re
import numpy as np
import os
import json 
import torch
import os
from nltk.util import ngrams
import pdb

def get_rouge(hyp_pathlist, ref_pathlist, config_path= './config', rouge_dir=None):
    path_data = []
    uttnames = []
    for i in range(len(hyp_pathlist)):
        path_data.append([hyp_pathlist[i], [ref_pathlist[i]]])
        uttnames.append(os.path.splitext(hyp_pathlist[i])[0].split('/')[-1])

    config_text = make_simple_config_text(path_data)
    config_path = config_path
    of = open(config_path,'w')
    of.write(config_text)
    of.close()
    uttnames.append('Average')
    df,avgfs,conf = compute_rouge(
        config_path, max_ngram=2, lcs=True, 
        remove_stopwords=False,stemmer=True,set_length = False, return_conf=True, rouge_dir=rouge_dir)
    df['data_ids'] = pd.Series(np.array(uttnames),index =df.index)
    avg = df.iloc[-1:].to_dict("records")[0]
    c = conf.to_dict("records")
    return avg,c,df

def get_ngrams(token_lst, n):
    """
    Return a list of tuples containing ngrams for token_lst
    """
    n_grams = set()
    for i in range(len(token_lst) - n + 1):
        n_grams.add(tuple(token_lst[i: i + n]))
    return n_grams

def ngram_overlap(candidate, summary):
    """
    As described in section 3 in https://arxiv.org/pdf/1903.10318
    summary: list of sentence strings
    candidate: sentence string
    """
    candidate_trigrams = get_ngrams(candidate.split(), 3)
    for sentence in summary:
        sentence_trigrams = get_ngrams(sentence.split(), 3)
        if len(candidate_trigrams.intersection(sentence_trigrams)) > 0:
            return True
    return False